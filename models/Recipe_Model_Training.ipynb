{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"header_cell\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"# Recipe Model Training on Google Colab\\n\",\n",
    "        \"\\n\",\n",
    "        \"This notebook trains a Flan-T5 Small model on recipe data to generate ingredients and directions from recipe titles.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"setup_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## 1. Mount Google Drive & Setup Environment\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"mount_drive\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Mount Google Drive\\n\",\n",
    "        \"from google.colab import drive\\n\",\n",
    "        \"drive.mount('/content/drive')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Change this path to match your actual folder structure\\n\",\n",
    "        \"BASE_PROJECT_PATH = \\\"/content/drive/MyDrive/ml_pipeline\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Print files to verify\\n\",\n",
    "        \"!ls -la $BASE_PROJECT_PATH\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"install_requirements\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Install required packages\\n\",\n",
    "        \"%cd $BASE_PROJECT_PATH\\n\",\n",
    "        \"!pip install transformers datasets torch sacrebleu rouge-score pandas pyyaml\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"create_symlink\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Create a symlink for easier access\\n\",\n",
    "        \"!ln -sf $BASE_PROJECT_PATH /content/recipe-monk\\n\",\n",
    "        \"%cd /content/recipe-monk\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Verify files are accessible\\n\",\n",
    "        \"!ls -la\\n\",\n",
    "        \"!cat params.yaml\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"data_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## 2. Verify Raw Data & Preprocess\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"check_raw_data\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Check raw data exists\\n\",\n",
    "        \"!ls -la data/raw/\\n\",\n",
    "        \"\\n\",\n",
    "        \"# View first few lines of the raw data\\n\",\n",
    "        \"!head -n 5 data/raw/recipes_data.csv\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"run_preprocessing\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Run the preprocessing script\\n\",\n",
    "        \"!python scripts/preprocess.py\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"check_processed_data\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Check processed data\\n\",\n",
    "        \"!ls -la data/processed/\\n\",\n",
    "        \"\\n\",\n",
    "        \"# View first few lines of processed data\\n\",\n",
    "        \"!head -n 5 data/processed/train.csv\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check number of rows in train and test files\\n\",\n",
    "        \"!echo \\\"Train file rows: $(wc -l < data/processed/train.csv)\\\"\\n\",\n",
    "        \"!echo \\\"Test file rows: $(wc -l < data/processed/test.csv)\\\"\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"debug_data_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## 3. Debug Data Files (if needed)\\n\",\n",
    "        \"\\n\",\n",
    "        \"If you encounter issues with the dataset loading, this section helps identify and fix problems.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"debug_data_loading\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Try loading the data with pandas to verify format\\n\",\n",
    "        \"try:\\n\",\n",
    "        \"    train_df = pd.read_csv('data/processed/train.csv')\\n\",\n",
    "        \"    test_df = pd.read_csv('data/processed/test.csv')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    print(f\\\"Train data shape: {train_df.shape}\\\")\\n\",\n",
    "        \"    print(f\\\"Test data shape: {test_df.shape}\\\")\\n\",\n",
    "        \"    print(\\\"\\\\nTrain data columns:\\\")\\n\",\n",
    "        \"    print(train_df.columns.tolist())\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Check for required columns\\n\",\n",
    "        \"    if 'input_text' in train_df.columns and 'target_text' in train_df.columns:\\n\",\n",
    "        \"        print(\\\"\\\\n✅ Required columns 'input_text' and 'target_text' found.\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Show a few examples\\n\",\n",
    "        \"        print(\\\"\\\\nExample inputs and targets:\\\")\\n\",\n",
    "        \"        for i in range(min(3, len(train_df))):\\n\",\n",
    "        \"            print(f\\\"\\\\nExample {i+1}:\\\")\\n\",\n",
    "        \"            print(f\\\"Input: {train_df['input_text'].iloc[i]}\\\")\\n\",\n",
    "        \"            print(f\\\"Target (first 100 chars): {train_df['target_text'].iloc[i][:100]}...\\\")\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        print(\\\"\\\\n❌ Required columns not found. Available columns:\\\")\\n\",\n",
    "        \"        print(train_df.columns.tolist())\\n\",\n",
    "        \"        \\n\",\n",
    "        \"except Exception as e:\\n\",\n",
    "        \"    print(f\\\"Error loading data: {e}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"fix_data_if_needed\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# This cell is for fixing data issues if needed\\n\",\n",
    "        \"# Uncomment and modify if your data needs fixes\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Example: If column names are wrong, rename them\\n\",\n",
    "        \"'''\\n\",\n",
    "        \"if 'input_text' not in train_df.columns and 'some_other_column' in train_df.columns:\\n\",\n",
    "        \"    # Rename columns\\n\",\n",
    "        \"    train_df = train_df.rename(columns={'some_other_column': 'input_text', 'another_column': 'target_text'})\\n\",\n",
    "        \"    test_df = test_df.rename(columns={'some_other_column': 'input_text', 'another_column': 'target_text'})\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Save fixed data\\n\",\n",
    "        \"    train_df.to_csv('data/processed/train_fixed.csv', index=False)\\n\",\n",
    "        \"    test_df.to_csv('data/processed/test_fixed.csv', index=False)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    print(\\\"Fixed data saved to train_fixed.csv and test_fixed.csv\\\")\\n\",\n",
    "        \"'''\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"training_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## 4. Training the Model\\n\",\n",
    "        \"\\n\",\n",
    "        \"Now let's train the Flan-T5 Small model on our recipe data.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"run_training\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# First, create the model output directory\\n\",\n",
    "        \"!mkdir -p models/flan_t5_small\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Run the training script\\n\",\n",
    "        \"!python scripts/train_model_colab.py\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"testing_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## 5. Testing the Trained Model\\n\",\n",
    "        \"\\n\",\n",
    "        \"Let's test our model with some example inputs.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"create_test_script\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"%%writefile scripts/test_model_colab.py\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"from transformers import T5Tokenizer, T5ForConditionalGeneration\\n\",\n",
    "        \"import yaml\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Load parameters\\n\",\n",
    "        \"with open(\\\"params.yaml\\\", \\\"r\\\") as f:\\n\",\n",
    "        \"    params = yaml.safe_load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Load model and tokenizer\\n\",\n",
    "        \"MODEL_DIR = params[\\\"model\\\"][\\\"output_dir\\\"]\\n\",\n",
    "        \"tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR)\\n\",\n",
    "        \"model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check for GPU availability\\n\",\n",
    "        \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n",
    "        \"model = model.to(device)\\n\",\n",
    "        \"print(f\\\"Using device: {device}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Test with sample inputs\\n\",\n",
    "        \"sample_inputs = [\\n\",\n",
    "        \"    \\\"Generate ingredients and directions for: Chicken Curry\\\",\\n\",\n",
    "        \"    \\\"Generate ingredients and directions for: Chocolate Cake\\\",\\n\",\n",
    "        \"    \\\"Generate ingredients and directions for: Vegetable Soup\\\"\\n\",\n",
    "        \"]\\n\",\n",
    "        \"\\n\",\n",
    "        \"for input_text in sample_inputs:\\n\",\n",
    "        \"    # Tokenize and generate\\n\",\n",
    "        \"    inputs = tokenizer(input_text, return_tensors=\\\"pt\\\").to(device)\\n\",\n",
    "        \"    outputs = model.generate(\\n\",\n",
    "        \"        inputs.input_ids, \\n\",\n",
    "        \"        max_length=512, \\n\",\n",
    "        \"        num_beams=4, \\n\",\n",
    "        \"        early_stopping=True\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Decode and print\\n\",\n",
    "        \"    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    print(f\\\"\\\\n{'='*50}\\\")\\n\",\n",
    "        \"    print(f\\\"INPUT: {input_text}\\\")\\n\",\n",
    "        \"    print(f\\\"{'='*50}\\\")\\n\",\n",
    "        \"    print(f\\\"OUTPUT:\\\\n{generated_text}\\\")\\n\",\n",
    "        \"    print(f\\\"{'='*50}\\\\n\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"run_test_script\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Run the test script\\n\",\n",
    "        \"!python scripts/test_model_colab.py\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"saving_model_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## 6. Saving and Downloading the Model\\n\",\n",
    "        \"\\n\",\n",
    "        \"The model is already saved to your Google Drive, but you can also download a copy.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"id\": \"download_model\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Zip the model for easier download\\n\",\n",
    "        \"!zip -r /content/flan_t5_recipe_model.zip models/flan_t5_small/\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Download the zipped model\\n\",\n",
    "        \"from google.colab import files\\n\",\n",
    "        \"files.download('/content/flan_t5_recipe_model.zip')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"troubleshooting_section\"\n",
    "      },\n",
    "      \"source\": [\n",
    "        \"## Troubleshooting\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Common Issues and Solutions:\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. **Memory issues**: Reduce batch size in params.yaml or reduce max sequence length\\n\",\n",
    "        \"2. **Dataset loading errors**: Use the alternative dataset loading method (pandas to datasets conversion)\\n\",\n",
    "        \"3. **Training too slow**: Reduce number of epochs or train on a subset of data\\n\",\n",
    "        \"4. **Model loading errors**: Check if the model was saved correctly (look for files in models/flan_t5_small/)\\n\",\n",
    "        \"5. **Path issues**: Make sure BASE_PROJECT_PATH is correctly pointing to your project in Google Drive\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"name\": \"Recipe_Model_Training.ipynb\",\n",
    "      \"provenance\": [],\n",
    "      \"collapsed_sections\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    },\n",
    "    \"accelerator\": \"GPU\",\n",
    "    \"gpuClass\": \"standard\"\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
